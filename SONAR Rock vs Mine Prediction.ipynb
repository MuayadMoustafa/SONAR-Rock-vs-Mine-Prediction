{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6af7a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:25:20.817536Z",
     "start_time": "2022-12-27T14:25:18.772436Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161a9fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:25:42.613877Z",
     "start_time": "2022-12-27T14:25:42.527881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Machine_Learning_Projects-main/SONAR_Rock_vs_Mine_Prediction/Copy of sonar data - Copy of sonar data.csv', header=None)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60060162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:25:58.214758Z",
     "start_time": "2022-12-27T14:25:58.037651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb9296b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:26:18.375025Z",
     "start_time": "2022-12-27T14:26:18.351022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a28f63b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:27:59.539201Z",
     "start_time": "2022-12-27T14:27:59.519202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3645848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:28:03.052209Z",
     "start_time": "2022-12-27T14:28:02.750212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='60', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=60, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b437dd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:28:47.175538Z",
     "start_time": "2022-12-27T14:28:47.143542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.034989</td>\n",
       "      <td>0.045544</td>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>0.086715</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>0.128359</td>\n",
       "      <td>0.149832</td>\n",
       "      <td>0.213492</td>\n",
       "      <td>0.251022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.006930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.062028</td>\n",
       "      <td>0.096224</td>\n",
       "      <td>0.114180</td>\n",
       "      <td>0.117596</td>\n",
       "      <td>0.137392</td>\n",
       "      <td>0.159325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012311</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.006024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "60                                                                         \n",
       "M   0.034989  0.045544  0.050720  0.064768  0.086715  0.111864  0.128359   \n",
       "R   0.022498  0.030303  0.035951  0.041447  0.062028  0.096224  0.114180   \n",
       "\n",
       "          7         8         9   ...        50        51        52        53  \\\n",
       "60                                ...                                           \n",
       "M   0.149832  0.213492  0.251022  ...  0.019352  0.016014  0.011643  0.012185   \n",
       "R   0.117596  0.137392  0.159325  ...  0.012311  0.010453  0.009640  0.009518   \n",
       "\n",
       "          54        55        56        57        58        59  \n",
       "60                                                              \n",
       "M   0.009923  0.008914  0.007825  0.009060  0.008695  0.006930  \n",
       "R   0.008567  0.007430  0.007814  0.006677  0.007078  0.006024  \n",
       "\n",
       "[2 rows x 60 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(60).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10a4ca10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:32:38.285742Z",
     "start_time": "2022-12-27T14:32:38.263744Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns= 60 , axis = 1 ) \n",
    "y = df[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d02d98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:32:40.472337Z",
     "start_time": "2022-12-27T14:32:40.462333Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X ,y , test_size = 0.2 , shuffle = True , random_state = 1 , stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fcb705e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:32:50.987442Z",
     "start_time": "2022-12-27T14:32:50.974336Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_prediction = model.predict(X_train)\n",
    "train_data_accuracy = accuracy_score(train_data_prediction , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebe43eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:32:54.032407Z",
     "start_time": "2022-12-27T14:32:54.022408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'84.33734939759037 %'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_data_accuracy * 100) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a5077e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:32:58.215054Z",
     "start_time": "2022-12-27T14:32:58.190030Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a315a502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:33:00.665003Z",
     "start_time": "2022-12-27T14:33:00.598007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              M     R  accuracy  macro avg  weighted avg\n",
      "precision   1.0   1.0       1.0        1.0           1.0\n",
      "recall      1.0   1.0       1.0        1.0           1.0\n",
      "f1-score    1.0   1.0       1.0        1.0           1.0\n",
      "support    89.0  77.0       1.0      166.0         166.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[89  0]\n",
      " [ 0 77]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 69.05%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   M          R  accuracy  macro avg  weighted avg\n",
      "precision   0.764706   0.640000  0.690476   0.702353      0.705322\n",
      "recall      0.590909   0.800000  0.690476   0.695455      0.690476\n",
      "f1-score    0.666667   0.711111  0.690476   0.688889      0.687831\n",
      "support    22.000000  20.000000  0.690476  42.000000     42.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[13  9]\n",
      " [ 4 16]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=100)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1ff601a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:33:58.584458Z",
     "start_time": "2022-12-27T14:33:23.454456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n",
      "Best paramters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'})\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 86.75%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   M          R  accuracy   macro avg  weighted avg\n",
      "precision   0.838384   0.910448   0.86747    0.874416      0.871811\n",
      "recall      0.932584   0.792208   0.86747    0.862396      0.867470\n",
      "f1-score    0.882979   0.847222   0.86747    0.865100      0.866393\n",
      "support    89.000000  77.000000   0.86747  166.000000    166.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[83  6]\n",
      " [16 61]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 73.81%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   M          R  accuracy  macro avg  weighted avg\n",
      "precision   0.761905   0.714286  0.738095   0.738095      0.739229\n",
      "recall      0.727273   0.750000  0.738095   0.738636      0.738095\n",
      "f1-score    0.744186   0.731707  0.738095   0.737947      0.738244\n",
      "support    22.000000  20.000000  0.738095  42.000000     42.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[16  6]\n",
      " [ 5 15]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"criterion\":(\"gini\", \"entropy\"), \n",
    "    \"splitter\":(\"best\", \"random\"), \n",
    "    \"max_depth\":(list(range(1, 20))), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1, 20)), \n",
    "}\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(**best_params)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b704c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:36:03.829267Z",
     "start_time": "2022-12-27T14:36:03.557267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              M     R  accuracy  macro avg  weighted avg\n",
      "precision   1.0   1.0       1.0        1.0           1.0\n",
      "recall      1.0   1.0       1.0        1.0           1.0\n",
      "f1-score    1.0   1.0       1.0        1.0           1.0\n",
      "support    89.0  77.0       1.0      166.0         166.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[89  0]\n",
      " [ 0 77]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 78.57%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   M          R  accuracy  macro avg  weighted avg\n",
      "precision   0.760000   0.823529  0.785714   0.791765      0.790252\n",
      "recall      0.863636   0.700000  0.785714   0.781818      0.785714\n",
      "f1-score    0.808511   0.756757  0.785714   0.782634      0.783866\n",
      "support    22.000000  20.000000  0.785714  42.000000     42.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[19  3]\n",
      " [ 6 14]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ab094ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:39:24.917857Z",
     "start_time": "2022-12-27T14:36:31.038859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\A\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramters: {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True})\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              M     R  accuracy  macro avg  weighted avg\n",
      "precision   1.0   1.0       1.0        1.0           1.0\n",
      "recall      1.0   1.0       1.0        1.0           1.0\n",
      "f1-score    1.0   1.0       1.0        1.0           1.0\n",
      "support    89.0  77.0       1.0      166.0         166.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[89  0]\n",
      " [ 0 77]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 78.57%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   M          R  accuracy  macro avg  weighted avg\n",
      "precision   0.782609   0.789474  0.785714   0.786041      0.785878\n",
      "recall      0.818182   0.750000  0.785714   0.784091      0.785714\n",
      "f1-score    0.800000   0.769231  0.785714   0.784615      0.785348\n",
      "support    22.000000  20.000000  0.785714  42.000000     42.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[18  4]\n",
      " [ 5 15]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = RandomizedSearchCV(estimator=rf_clf, scoring='f1',param_distributions=random_grid, n_iter=100, cv=3, \n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "rf_best_params = rf_cv.best_params_\n",
    "print(f\"Best paramters: {rf_best_params})\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(**rf_best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b5af56a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:55:21.840754Z",
     "start_time": "2022-12-27T14:40:14.318758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 768 candidates, totalling 2304 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\A\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': True, 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 89.16%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   M          R  accuracy   macro avg  weighted avg\n",
      "precision   0.858586   0.940299  0.891566    0.899442      0.896489\n",
      "recall      0.955056   0.818182  0.891566    0.886619      0.891566\n",
      "f1-score    0.904255   0.875000  0.891566    0.889628      0.890685\n",
      "support    89.000000  77.000000  0.891566  166.000000    166.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[85  4]\n",
      " [14 63]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 69.05%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   M          R  accuracy  macro avg  weighted avg\n",
      "precision   0.695652   0.684211  0.690476   0.689931      0.690204\n",
      "recall      0.727273   0.650000  0.690476   0.688636      0.690476\n",
      "f1-score    0.711111   0.666667  0.690476   0.688889      0.689947\n",
      "support    22.000000  20.000000  0.690476  42.000000     42.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[16  6]\n",
      " [ 7 13]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [100, 500, 1000, 1500]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [2, 3, 5]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4, 10]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"f1\", cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "best_params = rf_cv.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(**best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d0a871d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:56:42.472488Z",
     "start_time": "2022-12-27T14:56:42.462483Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70ea0c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:56:53.046629Z",
     "start_time": "2022-12-27T14:56:53.022632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tr = DecisionTreeClassifier(random_state= 42)\n",
    "tr.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3ebf118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:59:00.906022Z",
     "start_time": "2022-12-27T14:59:00.886026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.score(X_train, y_train)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "257e711c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:59:13.083018Z",
     "start_time": "2022-12-27T14:59:13.061018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.80952380952381"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tr.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4a1ee20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T14:59:23.082194Z",
     "start_time": "2022-12-27T14:59:23.060194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = SVC(C = 1.0, kernel = 'linear')\n",
    "tr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9737c7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T15:00:09.363641Z",
     "start_time": "2022-12-27T15:00:09.341446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.95238095238095"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tr.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c76b5c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T15:00:59.194886Z",
     "start_time": "2022-12-27T15:00:59.172885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24e7429b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T15:01:21.100294Z",
     "start_time": "2022-12-27T15:01:21.085222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.57142857142857"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04274bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T15:01:47.916745Z",
     "start_time": "2022-12-27T15:01:47.892747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "ac.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b84e9811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T15:01:57.748156Z",
     "start_time": "2022-12-27T15:01:57.388154Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\A\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.04761904761905"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ac.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7b61a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T15:02:11.377548Z",
     "start_time": "2022-12-27T15:02:11.348546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=2)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2dbf85d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T15:02:20.941905Z",
     "start_time": "2022-12-27T15:02:20.924908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.95238095238095"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f3249e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T15:03:23.197908Z",
     "start_time": "2022-12-27T15:03:23.181867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is Mine\n"
     ]
    }
   ],
   "source": [
    "input_data =np.asarray((0.0164,0.0173,0.0347,0.007,0.0187,0.0671,0.1056,0.0697,0.0962,0.0251,0.0801,0.1056,0.1266,0.089,0.0198,0.1133,0.2826,0.3234,0.3238,0.4333,0.6068,0.7652,0.9203,0.9719,0.9207,0.7545,0.8289,0.8907,0.7309,0.6896,0.5829,0.4935,0.3101,0.0306,0.0244,0.1108,0.1594,0.1371,0.0696,0.0452,0.062,0.1421,0.1597,0.1384,0.0372,0.0688,0.0867,0.0513,0.0092,0.0198,0.0118,0.009,0.0223,0.0179,0.0084,0.0068,0.0032,0.0035,0.0056,0.004)).reshape(1,-1)\n",
    "prediction = lr.predict(input_data)\n",
    "\n",
    "if(prediction == 'R') :\n",
    "  print (\"Peediction is Rock\")\n",
    "else : \n",
    "  print('prediction is Mine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
